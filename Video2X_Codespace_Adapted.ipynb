                # Plot quality analysis
                print("\\nüìä Generating quality visualization...")
                v2x.plot_quality_analysis(results)
                
            else:
                print("‚ùå Quality analysis failed")
                
        except Exception as e:
            print(f"‚ùå Error during quality analysis: {e}")
    else:
        print("‚ùå Video2X wrapper not available for quality analysis")
    
    # Show file comparison table
    print(f"\\nüìã File Comparison:")
    print(f"{'File':<30} {'Size (MB)':<12} {'Modified'}")
    print("-" * 60)
    
    for file_path in [input_file] + output_files:\n        if file_path.exists():
            size_mb = file_path.stat().st_size / (1024 * 1024)
            mod_time = datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M')
            print(f"{file_path.name:<30} {size_mb:<12.1f} {mod_time}")
"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Step 5: Batch Processing (Optional)\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"üîÑ Batch Processing Multiple Videos\")\n",
    "print(\"==================================\\n\")\n",
    "\n",
    "# Find all video files for batch processing\n",
    "video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}\n",
    "all_videos = [f for f in input_dir.iterdir() \n",
    "              if f.is_file() and f.suffix.lower() in video_extensions]\n",
    "\n",
    "if len(all_videos) <= 1:\n",
    "    print(\"üìÅ Only one video found. Batch processing not needed.\")\n",
    "    print(\"üí° Add more videos to the input directory for batch processing.\")\n",
    "else:\n",
    "    print(f\"üìπ Found {len(all_videos)} videos for potential batch processing:\")\n",
    "    for i, video in enumerate(all_videos, 1):\n",
    "        size_mb = video.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {video.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Batch processing configuration\n",
    "    batch_processors = ['realesrgan', 'anime4k']\n",
    "    batch_scales = [2, 4]\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è Batch Configuration:\")\n",
    "    print(f\"   Processors: {', '.join(batch_processors)}\")\n",
    "    print(f\"   Scales: {', '.join(map(str, batch_scales))}\")\n",
    "    \n",
    "    # Estimate total processing time\n",
    "    total_combinations = len(all_videos) * len(batch_processors) * len(batch_scales)\n",
    "    est_time_per_combo = 5  # minutes (conservative estimate)\n",
    "    total_est_time = total_combinations * est_time_per_combo\n",
    "    \n",
    "    print(f\"\\n‚è≥ Batch Processing Estimate:\")\n",
    "    print(f\"   Total combinations: {total_combinations}\")\n",
    "    print(f\"   Estimated time: ~{total_est_time/60:.1f} hours\")\n",
    "    \n",
    "    # Confirmation for batch processing\n",
    "    confirm_batch = input(f\"\\nüöÄ Start batch processing of {len(all_videos)} videos? (y/N): \")\n",
    "    \n",
    "    if confirm_batch.lower() in ['y', 'yes']:\n",
    "        print(\"\\nüîÑ Starting batch processing...\")\n",
    "        \n",
    "        if v2x:\n",
    "            try:\n",
    "                # Use enhanced batch analysis\n",
    "                results_df = v2x.batch_analyze(all_videos, batch_processors, batch_scales)\n",
    "                \n",
    "                if not results_df.empty:\n",
    "                    print(\"\\n‚úÖ Batch processing completed!\")\n",
    "                    print(\"\\nüìä Batch Results Summary:\")\n",
    "                    display(results_df)\n",
    "                    \n",
    "                    # Save results to CSV\n",
    "                    results_file = workspace_path / f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                    results_df.to_csv(results_file, index=False)\n",
    "                    print(f\"üíæ Results saved to: {results_file.name}\")\n",
    "                    \n",
    "                    # Create comparison visualization\n",
    "                    if len(results_df) > 1:\n",
    "                        plt.figure(figsize=(12, 8))\n",
    "                        \n",
    "                        # SSIM comparison\n",
    "                        plt.subplot(2, 1, 1)\n",
    "                        for processor in batch_processors:\n",
    "                            processor_data = results_df[results_df['processor'] == processor]\n",
    "                            plt.scatter(processor_data['scale'], processor_data['ssim_mean'], \n",
    "                                      label=processor, alpha=0.7, s=100)\n",
    "                        plt.xlabel('Scale Factor')\n",
    "                        plt.ylabel('SSIM Score')\n",
    "                        plt.title('Quality Comparison: SSIM Scores')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # PSNR comparison\n",
    "                        plt.subplot(2, 1, 2)\n",
    "                        for processor in batch_processors:\n",
    "                            processor_data = results_df[results_df['processor'] == processor]\n",
    "                            plt.scatter(processor_data['scale'], processor_data['psnr_mean'], \n",
    "                                      label=processor, alpha=0.7, s=100)\n",
    "                        plt.xlabel('Scale Factor')\n",
    "                        plt.ylabel('PSNR (dB)')\n",
    "                        plt.title('Quality Comparison: PSNR Scores')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                        \n",
    "                        # Best results summary\n",
    "                        print(\"\\nüèÜ Best Results:\")\n",
    "                        best_ssim = results_df.loc[results_df['ssim_mean'].idxmax()]\n",
    "                        best_psnr = results_df.loc[results_df['psnr_mean'].idxmax()]\n",
    "                        \n",
    "                        print(f\"   Best SSIM: {best_ssim['processor']} {best_ssim['scale']}x (SSIM: {best_ssim['ssim_mean']:.4f})\")\n",
    "                        print(f\"   Best PSNR: {best_psnr['processor']} {best_psnr['scale']}x (PSNR: {best_psnr['psnr_mean']:.2f} dB)\")\n",
    "                else:\n",
    "                    print(\"‚ùå Batch processing completed but no results generated\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error during batch processing: {e}\")\n",
    "        else:\n",
    "            print(\"‚ùå Video2X wrapper not available for batch processing\")\n",
    "    else:\n",
    "        print(\"‚èπÔ∏è Batch processing cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Step 6: Frame Interpolation (RIFE) - Alternative Processing\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"üé¨ Frame Interpolation with RIFE\")\n",
    "print(\"================================\\n\")\n",
    "\n",
    "if not input_file or not input_file.exists():\n",
    "    print(\"‚ùå Input file not specified. Please select a file first.\")\n",
    "else:\n",
    "    print(f\"üìπ Input: {input_file.name}\")\n",
    "    print(\"\\nüí° Frame interpolation increases video smoothness by generating intermediate frames.\")\n",
    "    print(\"‚ö†Ô∏è Note: RIFE processing may not work in all environments.\")\n",
    "    \n",
    "    # RIFE configuration widgets\n",
    "    rife_model_widget = widgets.Dropdown(\n",
    "        options=['rife', 'rife-HD', 'rife-UHD', 'rife-anime', 'rife-v4.6'],\n",
    "        value='rife-v4.6',\n",
    "        description='RIFE Model:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    frame_rate_mul_widget = widgets.IntSlider(\n",
    "        value=2,\n",
    "        min=2,\n",
    "        max=8,\n",
    "        step=1,\n",
    "        description='Frame Rate Multiplier:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    display(rife_model_widget)\n",
    "    display(frame_rate_mul_widget)\n",
    "    \n",
    "    # Information about RIFE models\n",
    "    rife_info = widgets.HTML(\n",
    "        value=\"\"\"\n",
    "        <div style='background-color: #f0f8ff; padding: 10px; border-radius: 5px; margin: 10px 0;'>\n",
    "        <h4>üéØ RIFE Model Guide:</h4>\n",
    "        <ul>\n",
    "        <li><b>rife-v4.6</b>: Latest model, best quality</li>\n",
    "        <li><b>rife-HD</b>: Optimized for 1080p content</li>\n",
    "        <li><b>rife-UHD</b>: Optimized for 4K content</li>\n",
    "        <li><b>rife-anime</b>: Specialized for anime content</li>\n",
    "        <li><b>Frame Rate 2x</b>: Doubles smoothness (30fps ‚Üí 60fps)</li>\n",
    "        <li><b>Frame Rate 4x+</b>: Very smooth but slower processing</li>\n",
    "        </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "    display(rife_info)\n",
    "    \n",
    "    # Generate output filename for RIFE\n",
    "    rife_output_filename = f\"{input_file.stem}_rife_{frame_rate_mul_widget.value}x{input_file.suffix}\"\n",
    "    rife_output_file = output_dir / rife_output_filename\n",
    "    \n",
    "    print(f\"\\nüì§ RIFE output will be saved as: {rife_output_filename}\")\n",
    "    \n",
    "    # RIFE processing execution\n",
    "    start_rife = input(\"\\nüöÄ Start RIFE frame interpolation? (y/N): \")\n",
    "    \n",
    "    if start_rife.lower() in ['y', 'yes']:\n",
    "        print(\"\\nüé¨ Starting RIFE Frame Interpolation...\")\n",
    "        \n",
    "        # Build RIFE command\n",
    "        rife_command = [\n",
    "            \"docker\", \"run\", \"--rm\",\n",
    "            \"-v\", f\"{workspace_path}:/host\",\n",
    "            \"ghcr.io/k4yt3x/video2x:latest\",\n",
    "            \"-i\", f\"input/{input_file.name}\",\n",
    "            \"-o\", f\"output/{rife_output_filename}\",\n",
    "            \"-p\", \"rife\",\n",
    "            \"--rife-model\", rife_model_widget.value,\n",
    "            \"--frame-rate-mul\", str(frame_rate_mul_widget.value)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            print(f\"‚öôÔ∏è Model: {rife_model_widget.value}\")\n",
    "            print(f\"üìà Frame rate multiplier: {frame_rate_mul_widget.value}x\")\n",
    "            print(\"üîÑ Processing... (this may take a while)\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            result = subprocess.run(rife_command, cwd=workspace_path, \n",
    "                                  capture_output=False, text=True)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            if result.returncode == 0 and rife_output_file.exists():\n",
    "                processing_time = end_time - start_time\n",
    "                print(f\"\\n‚úÖ RIFE processing completed!\")\n",
    "                print(f\"‚è±Ô∏è Processing time: {processing_time/60:.1f} minutes\")\n",
    "                print(f\"üìÅ Output saved to: {rife_output_file.name}\")\n",
    "                \n",
    "                # File size comparison\n",
    "                input_size = input_file.stat().st_size / (1024 * 1024)\n",
    "                output_size = rife_output_file.stat().st_size / (1024 * 1024)\n",
    "                print(f\"\\nüìä File Size Comparison:\")\n",
    "                print(f\"   Input:  {input_size:.1f} MB\")\n",
    "                print(f\"   Output: {output_size:.1f} MB\")\n",
    "                print(f\"   Ratio:  {output_size/input_size:.1f}x larger\")\n",
    "            else:\n",
    "                print(\"‚ùå RIFE processing failed\")\n",
    "                print(\"üí° RIFE may not work in all environments\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during RIFE processing: {e}\")\n",
    "    else:\n",
    "        print(\"‚èπÔ∏è RIFE processing cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Step 7: Results Summary and Export\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üìã Processing Summary and Export\")\n",
    "print(\"===============================\\n\")\n",
    "\n",
    "# Scan output directory for all processed files\n",
    "output_files = [f for f in output_dir.iterdir() \n",
    "                if f.is_file() and f.suffix.lower() in {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}]\n",
    "\n",
    "if not output_files:\n",
    "    print(\"üìÅ No processed videos found.\")\n",
    "    print(\"üí° Process some videos using the steps above.\")\n",
    "else:\n",
    "    print(f\"üìπ Found {len(output_files)} processed video(s):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    total_input_size = 0\n",
    "    total_output_size = 0\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for i, output_file in enumerate(sorted(output_files, key=lambda f: f.stat().st_mtime), 1):\n",
    "        # Extract processing info from filename\n",
    "        parts = output_file.stem.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            original_name = '_'.join(parts[:-2])\n",
    "            processor = parts[-2]\n",
    "            scale_info = parts[-1]\n",
    "        else:\n",
    "            original_name = output_file.stem\n",
    "            processor = \"unknown\"\n",
    "            scale_info = \"unknown\"\n",
    "        \n",
    "        # File stats\n",
    "        output_size = output_file.stat().st_size / (1024 * 1024)\n",
    "        mod_time = datetime.fromtimestamp(output_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "        # Try to find original file\n",
    "        original_file = None\n",
    "        for ext in ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm']:\n",
    "            potential_original = input_dir / f\"{original_name}{ext}\"\n",
    "            if potential_original.exists():\n",
    "                original_file = potential_original\n",
    "                break\n",
    "        \n",
    "        input_size = original_file.stat().st_size / (1024 * 1024) if original_file else 0\n",
    "        size_ratio = output_size / input_size if input_size > 0 else 0\n",
    "        \n",
    "        print(f\"{i:2d}. {output_file.name}\")\n",
    "        print(f\"    üìê Processor: {processor.upper()} ({scale_info})\")\n",
    "        print(f\"    üìÅ Size: {output_size:.1f} MB (original: {input_size:.1f} MB, ratio: {size_ratio:.1f}x)\")\n",
    "        print(f\"    üïí Created: {mod_time}\")\n",
    "        print()\n",
    "        \n",
    "        # Collect data for summary\n",
    "        summary_data.append({\n",
    "            'filename': output_file.name,\n",
    "            'original_name': original_name,\n",
    "            'processor': processor,\n",
    "            'scale_info': scale_info,\n",
    "            'output_size_mb': round(output_size, 1),\n",
    "            'input_size_mb': round(input_size, 1),\n",
    "            'size_ratio': round(size_ratio, 1),\n",
    "            'created_date': mod_time,\n",
    "            'file_path': str(output_file)\n",
    "        })\n",
    "        \n",
    "        total_output_size += output_size\n",
    "        total_input_size += input_size\n",
    "    \n",
    "    # Overall summary\n",
    "    print(f\"üìä Overall Summary:\")\n",
    "    print(f\"   üìπ Videos processed: {len(output_files)}\")\n",
    "    print(f\"   üìÅ Total input size: {total_input_size:.1f} MB\")\n",
    "    print(f\"   üìÅ Total output size: {total_output_size:.1f} MB\")\n",
    "    print(f\"   üìà Average size increase: {total_output_size/total_input_size:.1f}x\")\n",
    "    print(f\"   üíæ Storage used: {total_output_size:.1f} MB\")\n",
    "    \n",
    "    # Export summary\n",
    "    export_summary = input(\"\\nüíæ Export processing summary? (Y/n): \")\n",
    "    \n",
    "    if export_summary.lower() not in ['n', 'no']:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Export as JSON\n",
    "        json_file = workspace_path / f\"video2x_summary_{timestamp}.json\"\n",
    "        summary_export = {\n",
    "            'export_date': datetime.now().isoformat(),\n",
    "            'total_files': len(output_files),\n",
    "            'total_input_size_mb': round(total_input_size, 1),\n",
    "            'total_output_size_mb': round(total_output_size, 1),\n",
    "            'average_size_ratio': round(total_output_size/total_input_size, 1) if total_input_size > 0 else 0,\n",
    "            'files': summary_data\n",
    "        }\n",
    "        \n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(summary_export, f, indent=2)\n",
    "        \n",
    "        print(f\"‚úÖ Summary exported to: {json_file.name}\")\n",
    "        \n",
    "        # Export as CSV for easy analysis\n",
    "        if summary_data:\n",
    "            import pandas as pd\n",
    "            df = pd.DataFrame(summary_data)\n",
    "            csv_file = workspace_path / f\"video2x_summary_{timestamp}.csv\"\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            print(f\"‚úÖ CSV data exported to: {csv_file.name}\")\n",
    "    \n",
    "    print(f\"\\nüéØ All processed videos are in: {output_dir}\")\n",
    "    print(f\"üìÅ Access your results through VS Code file explorer\")\n",
    "    print(f\"\\nüéâ Video2X processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
    print(\"-\" * 60)\n",
    "    \n",
    "    for file_path in [input_file] + output_files:\n",
    "        if file_path.exists():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            mod_time = datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M')\n",
    "            print(f\"{file_path.name:<30} {size_mb:<12.1f} {mod_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Batch Processing (Optional)\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"üîÑ Batch Processing Multiple Videos\")\n",
    "print(\"==================================\\n\")\n",
    "\n",
    "# Find all video files for batch processing\n",
    "video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}\n",
    "all_videos = [f for f in input_dir.iterdir() \n",
    "              if f.is_file() and f.suffix.lower() in video_extensions]\n",
    "\n",
    "if len(all_videos) <= 1:\n",
    "    print(\"üìÅ Only one video found. Batch processing not needed.\")\n",
    "    print(\"üí° Add more videos to the input directory for batch processing.\")\n",
    "else:\n",
    "    print(f\"üìπ Found {len(all_videos)} videos for potential batch processing:\")\n",
    "    for i, video in enumerate(all_videos, 1):\n",
    "        size_mb = video.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {video.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Batch processing configuration\n",
    "    batch_processors = ['realesrgan', 'anime4k']\n",
    "    batch_scales = [2, 4]\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è Batch Configuration:\")\n",
    "    print(f\"   Processors: {', '.join(batch_processors)}\")\n",
    "    print(f\"   Scales: {', '.join(map(str, batch_scales))}\")\n",
    "    \n",
    "    # Estimate total processing time\n",
    "    total_combinations = len(all_videos) * len(batch_processors) * len(batch_scales)\n",
    "    est_time_per_combo = 5  # minutes (conservative estimate)\n",
    "    total_est_time = total_combinations * est_time_per_combo\n",
    "    \n",
    "    print(f\"\\n‚è≥ Batch Processing Estimate:\")\n",
    "    print(f\"   Total combinations: {total_combinations}\")\n",
    "    print(f\"   Estimated time: ~{total_est_time/60:.1f} hours\")\n",
    "    \n",
    "    # Confirmation for batch processing\n",
    "    confirm_batch = input(f\"\\nüöÄ Start batch processing of {len(all_videos)} videos? (y/N): \")\n",
    "    \n",
    "    if confirm_batch.lower() in ['y', 'yes']:\n",
    "        print(\"\\nüîÑ Starting batch processing...\")\n",
    "        \n",
    "        if v2x:\n",
    "            try:\n",
    "                # Use enhanced batch analysis\n",
    "                results_df = v2x.batch_analyze(all_videos, batch_processors, batch_scales)\n",
    "                \n",
    "                if not results_df.empty:\n",
    "                    print(\"\\n‚úÖ Batch processing completed!\")\n",
    "                    print(\"\\nüìä Batch Results Summary:\")\n",
    "                    display(results_df)\n",
    "                    \n",
    "                    # Save results to CSV\n",
    "                    results_file = workspace_path / f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                    results_df.to_csv(results_file, index=False)\n",
    "                    print(f\"üíæ Results saved to: {results_file.name}\")\n",
    "                    \n",
    "                    # Create comparison visualization\n",
    "                    if len(results_df) > 1:\n",
    "                        plt.figure(figsize=(12, 8))\n",
    "                        \n",
    "                        # SSIM comparison\n",
    "                        plt.subplot(2, 1, 1)\n",
    "                        for processor in batch_processors:\n",
    "                            processor_data = results_df[results_df['processor'] == processor]\n",
    "                            plt.scatter(processor_data['scale'], processor_data['ssim_mean'], \n",
    "                                      label=processor, alpha=0.7, s=100)\n",
    "                        plt.xlabel('Scale Factor')\n",
    "                        plt.ylabel('SSIM Score')\n",
    "                        plt.title('Quality Comparison: SSIM Scores')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # PSNR comparison\n",
    "                        plt.subplot(2, 1, 2)\n",
    "                        for processor in batch_processors:\n",
    "                            processor_data = results_df[results_df['processor'] == processor]\n",
    "                            plt.scatter(processor_data['scale'], processor_data['psnr_mean'], \n",
    "                                      label=processor, alpha=0.7, s=100)\n",
    "                        plt.xlabel('Scale Factor')\n",
    "                        plt.ylabel('PSNR (dB)')\n",
    "                        plt.title('Quality Comparison: PSNR Scores')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                        \n",
    "                        # Best results summary\n",
    "                        print(\"\\nüèÜ Best Results:\")\n",
    "                        best_ssim = results_df.loc[results_df['ssim_mean'].idxmax()]\n",
    "                        best_psnr = results_df.loc[results_df['psnr_mean'].idxmax()]\n",
    "                        \n",
    "                        print(f\"   Best SSIM: {best_ssim['processor']} {best_ssim['scale']}x (SSIM: {best_ssim['ssim_mean']:.4f})\")\n",
    "                        print(f\"   Best PSNR: {best_psnr['processor']} {best_psnr['scale']}x (PSNR: {best_psnr['psnr_mean']:.2f} dB)\")\n",
    "                else:\n",
    "                    print(\"‚ùå Batch processing completed but no results generated\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error during batch processing: {e}\")\n",
    "        else:\n",
    "            print(\"‚ùå Video2X wrapper not available for batch processing\")\n",
    "    else:\n",
    "        print(\"‚èπÔ∏è Batch processing cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Frame Interpolation (RIFE)\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"üé¨ Frame Interpolation with RIFE\")\n",
    "print(\"================================\\n\")\n",
    "\n",
    "if not input_file or not input_file.exists():\n",
    "    print(\"‚ùå Input file not specified. Please select a file first.\")\n",
    "else:\n",
    "    print(f\"üìπ Input: {input_file.name}\")\n",
    "    print(\"\\nüí° Frame interpolation increases video smoothness by generating intermediate frames.\")\n",
    "    print(\"‚ö†Ô∏è Note: RIFE processing may not work in all environments.\")\n",
    "    \n",
    "    # RIFE configuration widgets\n",
    "    rife_model_widget = widgets.Dropdown(\n",
    "        options=['rife', 'rife-HD', 'rife-UHD', 'rife-anime', 'rife-v4.6'],\n",
    "        value='rife-v4.6',\n",
    "        description='RIFE Model:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    frame_rate_mul_widget = widgets.IntSlider(\n",
    "        value=2,\n",
    "        min=2,\n",
    "        max=8,\n",
    "        step=1,\n",
    "        description='Frame Rate Multiplier:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    display(rife_model_widget)\n",
    "    display(frame_rate_mul_widget)\n",
    "    \n",
    "    # Information about RIFE models\n",
    "    rife_info = widgets.HTML(\n",
    "        value=\"\"\"\n",
    "        <div style='background-color: #f0f8ff; padding: 10px; border-radius: 5px; margin: 10px 0;'>\n",
    "        <h4>üéØ RIFE Model Guide:</h4>\n",
    "        <ul>\n",
    "        <li><b>rife-v4.6</b>: Latest model, best quality</li>\n",
    "        <li><b>rife-HD</b>: Optimized for 1080p content</li>\n",
    "        <li><b>rife-UHD</b>: Optimized for 4K content</li>\n",
    "        <li><b>rife-anime</b>: Specialized for anime content</li>\n",
    "        <li><b>Frame Rate 2x</b>: Doubles smoothness (30fps ‚Üí 60fps)</li>\n",
    "        <li><b>Frame Rate 4x+</b>: Very smooth but slower processing</li>\n",
    "        </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "    display(rife_info)\n",
    "    \n",
    "    # Generate output filename for RIFE\n",
    "    rife_output_filename = f\"{input_file.stem}_rife_{frame_rate_mul_widget.value}x{input_file.suffix}\"\n",
    "    rife_output_file = output_dir / rife_output_filename\n",
    "    \n",
    "    print(f\"\\nüì§ RIFE output will be saved as: {rife_output_filename}\")\n",
    "    \n",
    "    # RIFE processing execution\n",
    "    start_rife = input(\"\\nüöÄ Start RIFE frame interpolation? (y/N): \")\n",
    "    \n",
    "    if start_rife.lower() in ['y', 'yes']:\n",
    "        print(\"\\nüé¨ Starting RIFE Frame Interpolation...\")\n",
    "        \n",
    "        # Build RIFE command\n",
    "        rife_command = [\n",
    "            \"docker\", \"run\", \"--rm\",\n",
    "            \"-v\", f\"{workspace_path}:/host\",\n",
    "            \"ghcr.io/k4yt3x/video2x:latest\",\n",
    "            \"-i\", f\"input/{input_file.name}\",\n",
    "            \"-o\", f\"output/{rife_output_filename}\",\n",
    "            \"-p\", \"rife\",\n",
    "            \"--rife-model\", rife_model_widget.value,\n",
    "            \"--frame-rate-mul\", str(frame_rate_mul_widget.value)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            print(f\"‚öôÔ∏è Model: {rife_model_widget.value}\")\n",
    "            print(f\"üìà Frame rate multiplier: {frame_rate_mul_widget.value}x\")\n",
    "            print(\"üîÑ Processing... (this may take a while)\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            result = subprocess.run(rife_command, cwd=workspace_path, \n",
    "                                  capture_output=False, text=True)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            if result.returncode == 0 and rife_output_file.exists():\n",
    "                processing_time = end_time - start_time\n",
    "                print(f\"\\n‚úÖ RIFE processing completed!\")\n",
    "                print(f\"‚è±Ô∏è Processing time: {processing_time/60:.1f} minutes\")\n",
    "                print(f\"üìÅ Output saved to: {rife_output_file.name}\")\n",
    "                \n",
    "                # File size comparison\n",
    "                input_size = input_file.stat().st_size / (1024 * 1024)\n",
    "                output_size = rife_output_file.stat().st_size / (1024 * 1024)\n",
    "                print(f\"\\nüìä File Size Comparison:\")\n",
    "                print(f\"   Input:  {input_size:.1f} MB\")\n",
    "                print(f\"   Output: {output_size:.1f} MB\")\n",
    "                print(f\"   Ratio:  {output_size/input_size:.1f}x larger\")\n",
    "            else:\n",
    "                print(\"‚ùå RIFE processing failed\")\n",
    "                print(\"üí° RIFE may not work in all environments\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during RIFE processing: {e}\")\n",
    "    else:\n",
    "        print(\"‚èπÔ∏è RIFE processing cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Results Summary and Export\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üìã Processing Summary and Export\")\n",
    "print(\"===============================\\n\")\n",
    "\n",
    "# Scan output directory for all processed files\n",
    "output_files = [f for f in output_dir.iterdir() \n",
    "                if f.is_file() and f.suffix.lower() in {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}]\n",
    "\n",
    "if not output_files:\n",
    "    print(\"üìÅ No processed videos found.\")\n",
    "    print(\"üí° Process some videos using the steps above.\")\n",
    "else:\n",
    "    print(f\"üìπ Found {len(output_files)} processed video(s):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    total_input_size = 0\n",
    "    total_output_size = 0\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for i, output_file in enumerate(sorted(output_files, key=lambda f: f.stat().st_mtime), 1):\n",
    "        # Extract processing info from filename\n",
    "        parts = output_file.stem.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            original_name = '_'.join(parts[:-2])\n",
    "            processor = parts[-2]\n",
    "            scale_info = parts[-1]\n",
    "        else:\n",
    "            original_name = output_file.stem\n",
    "            processor = \"unknown\"\n",
    "            scale_info = \"unknown\"\n",
    "        \n",
    "        # File stats\n",
    "        output_size = output_file.stat().st_size / (1024 * 1024)\n",
    "        mod_time = datetime.fromtimestamp(output_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "        # Try to find original file\n",
    "        original_file = None\n",
    "        for ext in ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm']:\n",
    "            potential_original = input_dir / f\"{original_name}{ext}\"\n",
    "            if potential_original.exists():\n",
    "                original_file = potential_original\n",
    "                break\n",
    "        \n",
    "        input_size = original_file.stat().st_size / (1024 * 1024) if original_file else 0\n",
    "        size_ratio = output_size / input_size if input_size > 0 else 0\n",
    "        \n",
    "        print(f\"{i:2d}. {output_file.name}\")\n",
    "        print(f\"    üìê Processor: {processor.upper()} ({scale_info})\")\n",
    "        print(f\"    üìÅ Size: {output_size:.1f} MB (original: {input_size:.1f} MB, ratio: {size_ratio:.1f}x)\")\n",
    "        print(f\"    üïí Created: {mod_time}\")\n",
    "        print()\n",
    "        \n",
    "        # Collect data for summary\n",
    "        summary_data.append({\n",
    "            'filename': output_file.name,\n",
    "            'original_name': original_name,\n",
    "            'processor': processor,\n",
    "            'scale_info': scale_info,\n",
    "            'output_size_mb': round(output_size, 1),\n",
    "            'input_size_mb': round(input_size, 1),\n",
    "            'size_ratio': round(size_ratio, 1),\n",
    "            'created_date': mod_time,\n",
    "            'file_path': str(output_file)\n",
    "        })\n",
    "        \n",
    "        total_output_size += output_size\n",
    "        total_input_size += input_size\n",
    "    \n",
    "    # Overall summary\n",
    "    print(f\"üìä Overall Summary:\")\n",
    "    print(f\"   üìπ Videos processed: {len(output_files)}\")\n",
    "    print(f\"   üìÅ Total input size: {total_input_size:.1f} MB\")\n",
    "    print(f\"   üìÅ Total output size: {total_output_size:.1f} MB\")\n",
    "    print(f\"   üìà Average size increase: {total_output_size/total_input_size:.1f}x\")\n",
    "    print(f\"   üíæ Storage used: {total_output_size:.1f} MB\")\n",
    "    \n",
    "    # Export summary\n",
    "    export_summary = input(\"\\nüíæ Export processing summary? (Y/n): \")\n",
    "    \n",
    "    if export_summary.lower() not in ['n', 'no']:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Export as JSON\n",
    "        json_file = workspace_path / f\"video2x_summary_{timestamp}.json\"\n",
    "        summary_export = {\n",
    "            'export_date': datetime.now().isoformat(),\n",
    "            'total_files': len(output_files),\n",
    "            'total_input_size_mb': round(total_input_size, 1),\n",
    "            'total_output_size_mb': round(total_output_size, 1),\n",
    "            'average_size_ratio': round(total_output_size/total_input_size, 1) if total_input_size > 0 else 0,\n",
    "            'files': summary_data\n",
    "        }\n",
    "        \n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(summary_export, f, indent=2)\n",
    "        \n",
    "        print(f\"‚úÖ Summary exported to: {json_file.name}\")\n",
    "        \n",
    "        # Export as CSV for easy analysis\n",
    "        if summary_data:\n",
    "            import pandas as pd\n",
    "            df = pd.DataFrame(summary_data)\n",
    "            csv_file = workspace_path / f\"video2x_summary_{timestamp}.csv\"\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            print(f\"‚úÖ CSV data exported to: {csv_file.name}\")\n",
    "    \n",
    "    print(f\"\\nüéØ All processed videos are in: {output_dir}\")\n",
    "    print(f\"üìÅ Access your results through VS Code file explorer\")\n",
    "    print(f\"\\nüéâ Video2X processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
