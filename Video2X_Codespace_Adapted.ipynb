                # PSNR over time\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot(results['frame_indices'], results['psnr_scores'], 'go-', alpha=0.7, linewidth=2)\n",
    "                plt.axhline(y=results['psnr_mean'], color='red', linestyle='--',\n",
    "                           label=f'Mean: {results[\"psnr_mean\"]:.2f} dB')\n",
    "                plt.fill_between(results['frame_indices'], \n",
    "                               results['psnr_mean'] - results['psnr_std'],\n",
    "                               results['psnr_mean'] + results['psnr_std'], \n",
    "                               alpha=0.2, color='red')\n",
    "                plt.xlabel('Frame Index')\n",
    "                plt.ylabel('PSNR (dB)')\n",
    "                plt.title('Peak Signal-to-Noise Ratio Over Time')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå Quality analysis failed\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during quality analysis: {e}\")\n",
    "    else:\n",
    "        print(\"‚ùå Video2X wrapper not available for quality analysis\")\n",
    "    \n",
    "    # Show comprehensive file comparison table\n",
    "    print(f\"\\nüìã File Comparison Summary:\")\n",
    "    print(f\"{'File':<35} {'Size (MB)':<12} {'Type':<10} {'Modified'}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for file_path in [input_file] + output_files:\n",
    "        if file_path.exists():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            mod_time = datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M')\n",
    "            file_type = \"Original\" if file_path == input_file else \"Processed\"\n",
    "            print(f\"{file_path.name:<35} {size_mb:<12.1f} {file_type:<10} {mod_time}\")\n",
    "    \n",
    "    print(f\"\\nüìç All files located in: {output_dir.parent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BatchProcessing"
   },
   "outputs": [],
   "source": [
    "#@title ## Step 4: Batch Processing (Optional)\n",
    "\n",
    "#@markdown **Process multiple videos with different settings for comparison.**\n",
    "\n",
    "#@markdown - üîÑ Processes all videos in input directory\n",
    "#@markdown - üìä Generates comparative analysis\n",
    "#@markdown - üíæ Exports results to CSV for further analysis\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"üîÑ Batch Processing Multiple Videos\")\n",
    "print(\"==================================\\n\")\n",
    "\n",
    "# Find all video files for batch processing\n",
    "video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}\n",
    "all_videos = [f for f in input_dir.iterdir() \n",
    "              if f.is_file() and f.suffix.lower() in video_extensions]\n",
    "\n",
    "if len(all_videos) <= 1:\n",
    "    print(\"üìÅ Only one video found. Batch processing not needed.\")\n",
    "    print(\"üí° Add more videos to the input directory for batch processing.\")\n",
    "else:\n",
    "    print(f\"üìπ Found {len(all_videos)} videos for potential batch processing:\")\n",
    "    for i, video in enumerate(all_videos, 1):\n",
    "        size_mb = video.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {video.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Batch processing configuration\n",
    "    batch_processors = ['realesrgan', 'anime4k']\n",
    "    batch_scales = [2, 4]\n",
    "    \n",
    "    print(f\"\\n‚öôÔ∏è Batch Configuration:\")\n",
    "    print(f\"   Processors: {', '.join(batch_processors)}\")\n",
    "    print(f\"   Scales: {', '.join(map(str, batch_scales))}\")\n",
    "    \n",
    "    # Estimate total processing time\n",
    "    total_combinations = len(all_videos) * len(batch_processors) * len(batch_scales)\n",
    "    est_time_per_combo = 5  # minutes (conservative estimate)\n",
    "    total_est_time = total_combinations * est_time_per_combo\n",
    "    \n",
    "    print(f\"\\n‚è≥ Batch Processing Estimate:\")\n",
    "    print(f\"   Total combinations: {total_combinations}\")\n",
    "    print(f\"   Estimated time: ~{total_est_time/60:.1f} hours\")\n",
    "    \n",
    "    # Confirmation for batch processing\n",
    "    confirm_batch = input(f\"\\nüöÄ Start batch processing of {len(all_videos)} videos? (y/N): \")\n",
    "    \n",
    "    if confirm_batch.lower() in ['y', 'yes']:\n",
    "        print(\"\\nüîÑ Starting batch processing...\")\n",
    "        \n",
    "        if v2x:\n",
    "            try:\n",
    "                # Use enhanced batch analysis\n",
    "                results_df = v2x.batch_analyze(all_videos, batch_processors, batch_scales)\n",
    "                \n",
    "                if not results_df.empty:\n",
    "                    print(\"\\n‚úÖ Batch processing completed!\")\n",
    "                    print(\"\\nüìä Batch Results Summary:\")\n",
    "                    display(results_df)\n",
    "                    \n",
    "                    # Save results to CSV\n",
    "                    results_file = workspace_path / f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                    results_df.to_csv(results_file, index=False)\n",
    "                    print(f\"üíæ Results saved to: {results_file.name}\")\n",
    "                    \n",
    "                    # Create comprehensive comparison visualization\n",
    "                    if len(results_df) > 1:\n",
    "                        plt.figure(figsize=(15, 10))\n",
    "                        \n",
    "                        # SSIM comparison by processor\n",
    "                        plt.subplot(2, 2, 1)\n",
    "                        sns.boxplot(data=results_df, x='processor', y='ssim_mean')\n",
    "                        plt.title('SSIM Quality by Processor')\n",
    "                        plt.ylabel('SSIM Score')\n",
    "                        \n",
    "                        # PSNR comparison by processor\n",
    "                        plt.subplot(2, 2, 2)\n",
    "                        sns.boxplot(data=results_df, x='processor', y='psnr_mean')\n",
    "                        plt.title('PSNR Quality by Processor')\n",
    "                        plt.ylabel('PSNR (dB)')\n",
    "                        \n",
    "                        # SSIM vs Scale\n",
    "                        plt.subplot(2, 2, 3)\n",
    "                        for processor in batch_processors:\n",
    "                            processor_data = results_df[results_df['processor'] == processor]\n",
    "                            plt.scatter(processor_data['scale'], processor_data['ssim_mean'], \n",
    "                                      label=processor, alpha=0.7, s=100)\n",
    "                        plt.xlabel('Scale Factor')\n",
    "                        plt.ylabel('SSIM Score')\n",
    "                        plt.title('Quality vs Scale Factor')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        # Processing efficiency (quality vs file size increase)\n",
    "                        plt.subplot(2, 2, 4)\n",
    "                        colors = {'realesrgan': 'blue', 'anime4k': 'red'}\n",
    "                        for processor in batch_processors:\n",
    "                            processor_data = results_df[results_df['processor'] == processor]\n",
    "                            if len(processor_data) > 0:\n",
    "                                plt.scatter(processor_data['ssim_mean'], processor_data['scale'], \n",
    "                                          c=colors.get(processor, 'gray'), label=processor, alpha=0.7, s=100)\n",
    "                        plt.xlabel('SSIM Quality')\n",
    "                        plt.ylabel('Scale Factor')\n",
    "                        plt.title('Quality vs Scale Efficiency')\n",
    "                        plt.legend()\n",
    "                        plt.grid(True, alpha=0.3)\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                        \n",
    "                        # Best results summary\n",
    "                        print(\"\\nüèÜ Best Results Summary:\")\n",
    "                        best_ssim = results_df.loc[results_df['ssim_mean'].idxmax()]\n",
    "                        best_psnr = results_df.loc[results_df['psnr_mean'].idxmax()]\n",
    "                        \n",
    "                        print(f\"   ü•á Best SSIM: {best_ssim['processor']} {best_ssim['scale']}x\")\n",
    "                        print(f\"      Quality: SSIM={best_ssim['ssim_mean']:.4f}, PSNR={best_ssim['psnr_mean']:.2f} dB\")\n",
    "                        print(f\"   ü•á Best PSNR: {best_psnr['processor']} {best_psnr['scale']}x\")\n",
    "                        print(f\"      Quality: SSIM={best_psnr['ssim_mean']:.4f}, PSNR={best_psnr['psnr_mean']:.2f} dB\")\n",
    "                        \n",
    "                        # Recommendations\n",
    "                        print(f\"\\nüí° Recommendations:\")\n",
    "                        avg_quality = results_df.groupby('processor')[['ssim_mean', 'psnr_mean']].mean()\n",
    "                        for processor in batch_processors:\n",
    "                            if processor in avg_quality.index:\n",
    "                                avg_ssim = avg_quality.loc[processor, 'ssim_mean']\n",
    "                                avg_psnr = avg_quality.loc[processor, 'psnr_mean']\n",
    "                                print(f\"   ‚Ä¢ {processor.upper()}: Avg SSIM={avg_ssim:.4f}, Avg PSNR={avg_psnr:.2f} dB\")\n",
    "                        \n",
    "                else:\n",
    "                    print(\"‚ùå Batch processing completed but no results generated\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error during batch processing: {e}\")\n",
    "        else:\n",
    "            print(\"‚ùå Video2X wrapper not available for batch processing\")\n",
    "    else:\n",
    "        print(\"‚èπÔ∏è Batch processing cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ResultsSummary"
   },
   "outputs": [],
   "source": [
    "#@title ## Step 5: Results Summary and Export\n",
    "\n",
    "#@markdown **Generate comprehensive summary and export results.**\n",
    "\n",
    "#@markdown - üìã Complete processing summary\n",
    "#@markdown - üíæ Export to JSON and CSV formats\n",
    "#@markdown - üìä Storage usage analysis\n",
    "#@markdown - üéØ Processing recommendations\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üìã Comprehensive Results Summary\")\n",
    "print(\"===============================\\n\")\n",
    "\n",
    "# Scan output directory for all processed files\n",
    "output_files = [f for f in output_dir.iterdir() \n",
    "                if f.is_file() and f.suffix.lower() in {'.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm'}]\n",
    "\n",
    "if not output_files:\n",
    "    print(\"üìÅ No processed videos found.\")\n",
    "    print(\"üí° Process some videos using the steps above.\")\n",
    "else:\n",
    "    print(f\"üìπ Found {len(output_files)} processed video(s):\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    total_input_size = 0\n",
    "    total_output_size = 0\n",
    "    summary_data = []\n",
    "    \n",
    "    for i, output_file in enumerate(sorted(output_files, key=lambda f: f.stat().st_mtime), 1):\n",
    "        # Extract processing info from filename\n",
    "        parts = output_file.stem.split('_')\n",
    "        if len(parts) >= 3:\n",
    "            original_name = '_'.join(parts[:-2])\n",
    "            processor = parts[-2]\n",
    "            scale_info = parts[-1]\n",
    "        else:\n",
    "            original_name = output_file.stem\n",
    "            processor = \"unknown\"\n",
    "            scale_info = \"unknown\"\n",
    "        \n",
    "        # File stats\n",
    "        output_size = output_file.stat().st_size / (1024 * 1024)\n",
    "        mod_time = datetime.fromtimestamp(output_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "        # Try to find original file\n",
    "        original_file = None\n",
    "        for ext in ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm']:\n",
    "            potential_original = input_dir / f\"{original_name}{ext}\"\n",
    "            if potential_original.exists():\n",
    "                original_file = potential_original\n",
    "                break\n",
    "        \n",
    "        input_size = original_file.stat().st_size / (1024 * 1024) if original_file else 0\n",
    "        size_ratio = output_size / input_size if input_size > 0 else 0\n",
    "        \n",
    "        print(f\"{i:2d}. {output_file.name}\")\n",
    "        print(f\"    üìê Processor: {processor.upper()} ({scale_info})\")\n",
    "        print(f\"    üìÅ Size: {output_size:.1f} MB (original: {input_size:.1f} MB, ratio: {size_ratio:.1f}x)\")\n",
    "        print(f\"    üïí Created: {mod_time}\")\n",
    "        \n",
    "        # Add quality info if available\n",
    "        if original_file and v2x:\n",
    "            try:\n",
    "                results = v2x.analyze_quality(str(original_file), str(output_file), sample_frames=3)\n",
    "                if results:\n",
    "                    print(f\"    üìä Quality: SSIM={results['ssim_mean']:.3f}, PSNR={results['psnr_mean']:.1f} dB\")\n",
    "                    quality_ssim = results['ssim_mean']\n",
    "                    quality_psnr = results['psnr_mean']\n",
    "                else:\n",
    "                    quality_ssim = None\n",
    "                    quality_psnr = None\n",
    "            except:\n",
    "                quality_ssim = None\n",
    "                quality_psnr = None\n",
    "        else:\n",
    "            quality_ssim = None\n",
    "            quality_psnr = None\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Collect data for summary\n",
    "        summary_data.append({\n",
    "            'filename': output_file.name,\n",
    "            'original_name': original_name,\n",
    "            'processor': processor,\n",
    "            'scale_info': scale_info,\n",
    "            'output_size_mb': round(output_size, 1),\n",
    "            'input_size_mb': round(input_size, 1),\n",
    "            'size_ratio': round(size_ratio, 1),\n",
    "            'quality_ssim': round(quality_ssim, 4) if quality_ssim else None,\n",
    "            'quality_psnr': round(quality_psnr, 2) if quality_psnr else None,\n",
    "            'created_date': mod_time,\n",
    "            'file_path': str(output_file)\n",
    "        })\n",
    "        \n",
    "        total_output_size += output_size\n",
    "        total_input_size += input_size\n",
    "    \n",
    "    # Overall summary\n",
    "    print(f\"üìä Overall Processing Summary:\")\n",
    "    print(f\"   üìπ Videos processed: {len(output_files)}\")\n",
    "    print(f\"   üìÅ Total input size: {total_input_size:.1f} MB\")\n",
    "    print(f\"   üìÅ Total output size: {total_output_size:.1f} MB\")\n",
    "    print(f\"   üìà Average size increase: {total_output_size/total_input_size:.1f}x\")\n",
    "    print(f\"   üíæ Storage used: {total_output_size:.1f} MB\")\n",
    "    print(f\"   ‚ö° Processing efficiency: {total_input_size/(total_output_size-total_input_size):.2f} MB input per MB increase\")\n",
    "    \n",
    "    # Processor analysis\n",
    "    if len(summary_data) > 1:\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        processor_stats = df.groupby('processor').agg({\n",
    "            'size_ratio': 'mean',\n",
    "            'quality_ssim': 'mean',\n",
    "            'quality_psnr': 'mean',\n",
    "            'filename': 'count'\n",
    "        }).round(3)\n",
    "        \n",
    "        print(f\"\\nüìà Processor Performance Summary:\")\n",
    "        for processor in processor_stats.index:\n",
    "            stats = processor_stats.loc[processor]\n",
    "            print(f\"   {processor.upper()}:\")\n",
    "            print(f\"     Files processed: {int(stats['filename'])}\")\n",
    "            print(f\"     Avg size ratio: {stats['size_ratio']:.1f}x\")\n",
    "            if not pd.isna(stats['quality_ssim']):\n",
    "                print(f\"     Avg SSIM: {stats['quality_ssim']:.3f}\")\n",
    "            if not pd.isna(stats['quality_psnr']):\n",
    "                print(f\"     Avg PSNR: {stats['quality_psnr']:.1f} dB\")\n",
    "    \n",
    "    # Export summary\n",
    "    export_summary = input(\"\\nüíæ Export processing summary? (Y/n): \")\n",
    "    \n",
    "    if export_summary.lower() not in ['n', 'no']:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Export as JSON\n",
    "        json_file = workspace_path / f\"video2x_summary_{timestamp}.json\"\n",
    "        summary_export = {\n",
    "            'export_date': datetime.now().isoformat(),\n",
    "            'total_files': len(output_files),\n",
    "            'total_input_size_mb': round(total_input_size, 1),\n",
    "            'total_output_size_mb': round(total_output_size, 1),\n",
    "            'average_size_ratio': round(total_output_size/total_input_size, 1) if total_input_size > 0 else 0,\n",
    "            'workspace_path': str(workspace_path),\n",
    "            'files': summary_data\n",
    "        }\n",
    "        \n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(summary_export, f, indent=2)\n",
    "        \n",
    "        print(f\"‚úÖ JSON summary exported to: {json_file.name}\")\n",
    "        \n",
    "        # Export as CSV for easy analysis\n",
    "        if summary_data:\n",
    "            df = pd.DataFrame(summary_data)\n",
    "            csv_file = workspace_path / f\"video2x_summary_{timestamp}.csv\"\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            print(f\"‚úÖ CSV data exported to: {csv_file.name}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Processing Complete!\")\n",
    "    print(f\"üìÅ All processed videos: {output_dir}\")\n",
    "    print(f\"üìä Summary files: {workspace_path}\")\n",
    "    print(f\"üîç Access files through VS Code file explorer\")\n",
    "    print(f\"\\nüéâ Video2X Codespace processing session complete!\")\n",
    "    \n",
    "    # Final recommendations\n",
    "    print(f\"\\nüí° Recommendations for future processing:\")\n",
    "    if total_input_size > 0:\n",
    "        avg_ratio = total_output_size / total_input_size\n",
    "        if avg_ratio > 5:\n",
    "            print(f\"   ‚Ä¢ Consider lower scale factors to reduce file sizes\")\n",
    "        elif avg_ratio < 2:\n",
    "            print(f\"   ‚Ä¢ Current settings provide good size efficiency\")\n",
    "    \n",
    "    if len(summary_data) > 1 and any(d['quality_ssim'] for d in summary_data if d['quality_ssim']):\n",
    "        avg_quality = np.mean([d['quality_ssim'] for d in summary_data if d['quality_ssim']])\n",
    "        if avg_quality > 0.95:\n",
    "            print(f\"   ‚Ä¢ Excellent quality achieved - current settings optimal\")\n",
    "        elif avg_quality < 0.8:\n",
    "            print(f\"   ‚Ä¢ Consider different processors or models for better quality\")\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Use batch processing for comparing different settings\")\n",
    "    print(f\"   ‚Ä¢ Export results for detailed analysis in spreadsheet applications\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
